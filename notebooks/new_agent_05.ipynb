{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import duckdb as db\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "# from pydantic import BaseModel\n",
    "from typing import Any, Dict, List, Tuple, TypedDict, Annotated\n",
    "from textwrap import dedent\n",
    "# from crewai_tools import tool, FileWriterTool\n",
    "from crewai import Agent, Crew, Process, Task\n",
    "# from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrewAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ChatGroq(\n",
    "#     model=\"llama3-8b-8192\",\n",
    "#     temperature = 0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ChatGoogleGenerativeAI(\n",
    "#     model='gemini-1.5-pro-exp-0801',\n",
    "#     temperature=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_list(file_path: str) -> List:\n",
    "    with open(file_path) as f:\n",
    "        s = f.read()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(folder_path: str):\n",
    "    file_list = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]\n",
    "    file_list.sort()\n",
    "    queries = []  \n",
    "\n",
    "    for sql_file in file_list:\n",
    "        q = query_list(join(folder_path,sql_file))\n",
    "        queries.append({\n",
    "            'query_name': sql_file[:-4],\n",
    "            'sql_code': q \n",
    "        })          \n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'sql_files/bn_beneficiario/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_analyst = Agent(\n",
    "    role = \"Senior Data Analyst\",\n",
    "    goal = \"Analyze and complicate SQL queries and extract the relationship between table name and column name of all tables in queries.\",\n",
    "    backstory=dedent(\n",
    "        \"\"\"\n",
    "        You're a highly specialized developed to dissect and understand complex SQL queries,\n",
    "        you could quickly and accurately extract essential information from intricate SQL statements, \n",
    "        including that ones that has many sub queries.\n",
    "        Your key traits are Analytical prowess, Attention to detail, Vast knowledge of SQL syntax \n",
    "        across multiple database systems.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    llm=model,\n",
    "    allow_delegation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_table_names = Task(\n",
    "    description=dedent(\n",
    "        \"\"\" \n",
    "        Search this SQL query {sql_code} for all table names involved.\n",
    "        It is very important not to ignore any tables. In complex queries, \n",
    "        there are some subqueries that must be observed carefully.\n",
    "        Do it line by line, get all table names and their alias when they are present.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    expected_output=\"List of distinct table names and alias present in the query.\",\n",
    "    agent=sql_analyst,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_tables_columns = Task(\n",
    "    description=dedent(\n",
    "        \"\"\"\n",
    "        Analyse this SQL querie {sql_code}.\n",
    "        Use the list of table names and their aliases extracted in the previous step and find the columns for each of these tables.\n",
    "        Then extract the names of related tables and columns. For this walkthrough, you will get all the table and column names used in this query.\n",
    "        Get just the table name and column name by following these patterns:\n",
    "        table_name;alias;columns_name\n",
    "        table1;alias1;columnName_n1\n",
    "        table1;alias1;columnName_n2\n",
    "        table2;alias2;columnName_n1\n",
    "        table2;alias2;columnName_n2\n",
    "        tableN;aliasN;columnName_n1\n",
    "        tableN;aliasN;columnName_n1\n",
    "        \"\"\"\n",
    "    ),\n",
    "    expected_output=\"CSV file\",\n",
    "    agent=sql_analyst,\n",
    "    context=[get_table_names]\n",
    "    #callback=lambda result: result_collector.add_result(result)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rules = Task(\n",
    "    description=dedent(\n",
    "        \"\"\"\n",
    "        Analyse this SQL querie {sql_code}.\n",
    "        Use the csv file generated in the previous step and find and extract following points:\n",
    "        * SQL code where sql functions are used such as NVL, DECODE, CASE, SUM, etc, or concatenations lets call it of rules.\n",
    "        * After rules we can find the alias for the column, the alias names are the final names given to the columns in the query. \n",
    "        Then step by step extract the column names, the alias, and the rule that gave rise to the alias.\n",
    "        Get column_name, alias, and rule, following these patterns only for columns were you find rules:\n",
    "        columns_name;alias;rule\n",
    "        columnName_n1;alias_n1;\"rule_n1\"\n",
    "        columnName_n2;alias_n2;\"rule_n2\"\n",
    "        columnName_n3;alias_n3;\"rule_n3\"\n",
    "        columnName_nn;alias_nn;\"rule_nn\"\n",
    "        \"\"\"\n",
    "    ),\n",
    "    expected_output=\"CSV file\",\n",
    "    agent=sql_analyst,\n",
    "    context=[extract_tables_columns]\n",
    "    #callback=lambda result: result_collector.add_result(result)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 15:16:53,654 - 130117974093824 - __init__.py-__init__:531 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "crew = Crew(\n",
    "    agents = [sql_analyst],\n",
    "    tasks = [get_table_names, extract_tables_columns, extract_rules],\n",
    "    process = Process.sequential,\n",
    "    verbose = 0,\n",
    "    memory=False,\n",
    "    output_log_file=\"crew.log\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "##self.export_to_csv()\n",
    "\n",
    "def save_to_parquet(data, filename, header: list):\n",
    "    # Split the string by newlines to get rows\n",
    "    rows = data.split('\\n')\n",
    "    \n",
    "    # Split each row by semicolons to get columns\n",
    "    formatted_data = [row.split(';') for row in rows]\n",
    "    \n",
    "    # Output filename\n",
    "    output_filename = f\"{'output'}/{filename}.parquet\"\n",
    "\n",
    "    df = pd.DataFrame(formatted_data, columns=header)\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table,output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    print(query['query_name'])\n",
    "    file_name = query['query_name']\n",
    "    result = crew.kickoff(inputs=query)\n",
    "    task_output = extract_tables_columns.output\n",
    "    save_to_parquet(task_output.raw, file_name, ['table','alias','column_name'])\n",
    "    task_output = extract_rules.output\n",
    "    save_to_parquet(task_output.raw, file_name+'_rules', ['column_name','alias','rule'])\n",
    "\n",
    "    #result_collector.add_result('export_tables_columns',output.raw,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = extract_rules.output.raw.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data = [row.split(';') for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(formatted_data, columns=['column_name','alias','rule'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(table,'output/teste.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processa CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error: Set operations can only apply to expressions with the same number of result columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBinderException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43;03m\"\"\"     \u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43;03m    with ben_ori as (\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43;03m        select * from 'output/01_beneficiario.csv' \u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43;03m        union all\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43;03m        select * from 'output/02_sam_familia_teto_pf.csv' \u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43;03m        union all\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43;03m        select * from 'output/03_1_busca_microsiga.csv'\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43;03m        union all\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43;03m        select * from 'output/03_2_sem_setor.csv'\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43;03m    ),\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43;03m    ben_rul as (\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43;03m        select \u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43;03m            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43;03m            alias,\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43;03m            rule\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43;03m        from 'output/01_beneficiario_rules.csv'\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43;03m        union all\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43;03m        select \u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43;03m            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43;03m            alias,\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;43;03m            rule\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43;03m        from 'output/02_sam_familia_teto_pf_rules.csv' \u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;43;03m        union all\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;43;03m        select \u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;43;03m            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;43;03m            alias,\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;43;03m            rule\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;43;03m        from 'output/03_1_busca_microsiga_rules.csv'\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;43;03m        union all\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43;03m        select \u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43;03m            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;43;03m            alias,\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;43;03m            rule        \u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;43;03m        from 'output/03_2_sem_setor_rules.csv'\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;43;03m    ),\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;43;03m    ben_dest as (\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;43;03m        select * from 'output/99_bn_beneficiario.csv'\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;43;03m    )\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;43;03m    select \u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;43;03m        distinct \u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;43;03m        ben_dest.*,\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;43;03m        ben_ori.*,\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;43;03m        ben_rul.*\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;43;03m    from ben_dest\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;43;03m    left join ben_ori \u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;43;03m    on(ben_ori.column_name = ben_dest.column_name)\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;43;03m    left join ben_rul\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;43;03m    on(ben_dest.colum_name_renamed = ben_rul.alias)\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;43;03m    order by ben_ori.column_name\u001b[39;49;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduckdb_output.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/repos/llm-agents-pentaho-mapping/.venv/lib/python3.10/site-packages/duckdb/__init__.py:457\u001b[0m, in \u001b[0;36msql\u001b[0;34m(query, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     conn \u001b[38;5;241m=\u001b[39m duckdb\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:default:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mBinderException\u001b[0m: Binder Error: Set operations can only apply to expressions with the same number of result columns"
     ]
    }
   ],
   "source": [
    "db.sql(\n",
    "\"\"\"     \n",
    "    with ben_ori as (\n",
    "        select * from 'output/01_beneficiario.csv' \n",
    "        union all\n",
    "        select * from 'output/02_sam_familia_teto_pf.csv' \n",
    "        union all\n",
    "        select * from 'output/03_1_busca_microsiga.csv'\n",
    "        union all\n",
    "        select * from 'output/03_2_sem_setor.csv'\n",
    "    ),\n",
    "    ben_rul as (\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/01_beneficiario_rules.csv'\n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/02_sam_familia_teto_pf_rules.csv' \n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/03_1_busca_microsiga_rules.csv'\n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule        \n",
    "        from 'output/03_2_sem_setor_rules.csv'\n",
    "    ),\n",
    "    ben_dest as (\n",
    "        select * from 'output/99_bn_beneficiario.csv'\n",
    "    )\n",
    "    select \n",
    "        distinct \n",
    "        ben_dest.*,\n",
    "        ben_ori.*,\n",
    "        ben_rul.*\n",
    "    from ben_dest\n",
    "    left join ben_ori \n",
    "    on(ben_ori.column_name = ben_dest.column_name)\n",
    "    left join ben_rul\n",
    "    on(ben_dest.colum_name_renamed = ben_rul.alias)\n",
    "    order by ben_ori.column_name\n",
    "\"\"\").to_csv('duckdb_output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error: Column \"column_name\" referenced that exists in the SELECT clause - but this column cannot be referenced before it is defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBinderException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43;03m\"\"\"     \u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43;03m        select \u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43;03m            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43;03m            alias,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43;03m            rule\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43;03m        from 'output/01_beneficiario_rules.csv'\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43;03m        union all\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43;03m        select \u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43;03m            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43;03m            alias,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43;03m            rule\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43;03m        from 'output/02_sam_familia_teto_pf_rules.csv' \u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43;03m        union all\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43;03m        select \u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43;03m            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43;03m            alias,\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43;03m            rule\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43;03m        from 'output/03_1_busca_microsiga_rules.csv'\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43;03m        union all\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43;03m        select \u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;43;03m            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43;03m            alias,\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;43;03m            rule        \u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;43;03m        from 'output/03_2_sem_setor_rules.csv'\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/llm-agents-pentaho-mapping/.venv/lib/python3.10/site-packages/duckdb/__init__.py:457\u001b[0m, in \u001b[0;36msql\u001b[0;34m(query, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     conn \u001b[38;5;241m=\u001b[39m duckdb\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:default:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mBinderException\u001b[0m: Binder Error: Column \"column_name\" referenced that exists in the SELECT clause - but this column cannot be referenced before it is defined"
     ]
    }
   ],
   "source": [
    "db.sql(\n",
    "\"\"\"     \n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/01_beneficiario_rules.csv'\n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/02_sam_familia_teto_pf_rules.csv' \n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/03_1_busca_microsiga_rules.csv'\n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule        \n",
    "        from 'output/03_2_sem_setor_rules.csv'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────┬──────────────┬──────────────────────┐\n",
       "│ column_name │    alias     │         rule         │\n",
       "│   varchar   │   varchar    │       varchar        │\n",
       "├─────────────┼──────────────┼──────────────────────┤\n",
       "│ CTT_DESC01  │ SETOR_UNIMED │ \"TRIM(B.CTT_DESC01)\" │\n",
       "│ RA_TELEFON  │ TELEFONE     │ \"TRIM(A.RA_TELEFON)\" │\n",
       "└─────────────┴──────────────┴──────────────────────┘"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.sql(\"select * from 'output/teste.parquet'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
