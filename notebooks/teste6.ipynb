{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List, Tuple\n",
    "import pandas as pd\n",
    "import pygraphviz as pgv\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pentaho_file_path = '../data/benef_transf.ktr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLAnalysisAgent:\n",
    "    def __init__(self, llm: Any):\n",
    "        self.llm = llm\n",
    "\n",
    "    def analyze(self, queries: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "        prompt_template = PromptTemplate(\n",
    "            input_variables=[\"sql_content\"],\n",
    "            template=\"\"\"\n",
    "            Analyze the following SQL query and provide insights on:\n",
    "            1. The purpose of the query\n",
    "            2. Tables and columns used\n",
    "            3. Any joins or complex operations\n",
    "            4. Potential optimizations\n",
    "            5. Suggested improvements for a data warehouse setting\n",
    "\n",
    "            SQL Query:\n",
    "            {sql_content}\n",
    "\n",
    "            Provide your analysis in a structured format.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        chain = RunnableSequence(prompt_template, self.llm)\n",
    "        analysis_results = []\n",
    "        for query in queries:\n",
    "            response = chain.invoke({\"sql_content\": query['sql']})\n",
    "            analysis_results.append({\n",
    "                \"step_name\": query['step_name'],\n",
    "                \"analysis\": response\n",
    "            })\n",
    "        \n",
    "        return analysis_results\n",
    "\n",
    "class WorkflowAnalysisAgent:\n",
    "    def __init__(self, llm: Any):\n",
    "        self.llm = llm\n",
    "\n",
    "    def analyze(self, sequence: List[tuple], queries: List[Dict[str, str]], sql_analysis: List[Dict[str, str]]) -> str:\n",
    "        prompt_template = PromptTemplate(\n",
    "            input_variables=[\"sequence\", \"queries\", \"sql_analysis\"],\n",
    "            template=\"\"\"\n",
    "            Analyze the following workflow and provide insights on:\n",
    "            1. The overall purpose of the workflow\n",
    "            2. The sequence of operations\n",
    "            3. Data flow between steps\n",
    "            4. Potential bottlenecks or inefficiencies\n",
    "            5. Suggested improvements for the workflow structure\n",
    "\n",
    "            Workflow Sequence:\n",
    "            {sequence}\n",
    "\n",
    "            Queries:\n",
    "            {queries}\n",
    "\n",
    "            SQL Analysis:\n",
    "            {sql_analysis}\n",
    "\n",
    "            Provide your analysis in a structured format.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        chain = RunnableSequence(prompt_template, self.llm)\n",
    "        response = chain.invoke({\n",
    "            \"sequence\": str(sequence),\n",
    "            \"queries\": str(queries),\n",
    "            \"sql_analysis\": str(sql_analysis)\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "\n",
    "class DocumentationAgent:\n",
    "    def __init__(self, llm: Any):\n",
    "        self.llm = llm\n",
    "\n",
    "    def generate(self, workflow_analysis: str, sql_analysis: List[Dict[str, str]]) -> str:\n",
    "        prompt_template = PromptTemplate(\n",
    "            input_variables=[\"workflow_analysis\", \"sql_analysis\"],\n",
    "            template=\"\"\"\n",
    "            Create a comprehensive markdown document that includes:\n",
    "            1. Executive Summary\n",
    "            2. Workflow Overview\n",
    "            3. Detailed Step Analysis\n",
    "            4. SQL Query Documentation\n",
    "            5. Identified Issues and Bottlenecks\n",
    "            6. Recommendations for Improvement\n",
    "\n",
    "            Use the following information:\n",
    "\n",
    "            Workflow Analysis:\n",
    "            {workflow_analysis}\n",
    "\n",
    "            SQL Analysis:\n",
    "            {sql_analysis}\n",
    "\n",
    "            Generate a well-structured markdown document.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        chain = RunnableSequence(prompt_template, self.llm)\n",
    "        response = chain.invoke({\n",
    "            \"workflow_analysis\": workflow_analysis,\n",
    "            \"sql_analysis\": str(sql_analysis)\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "\n",
    "class ProjectPlanningAgent:\n",
    "    def __init__(self, llm: Any):\n",
    "        self.llm = llm\n",
    "\n",
    "    def plan(self, documentation: str) -> str:\n",
    "        prompt_template = PromptTemplate(\n",
    "            input_variables=[\"documentation\"],\n",
    "            template=\"\"\"\n",
    "            Based on the provided documentation, create a project plan to recreate and improve the workflow:\n",
    "            1. Identify key objectives for the new project\n",
    "            2. Outline the main phases of the project\n",
    "            3. Suggest a new data warehouse structure with dimension and fact tables\n",
    "            4. Propose improvements for each step of the workflow\n",
    "            5. Recommend technologies and best practices to be used\n",
    "            6. Outline a testing and validation strategy\n",
    "\n",
    "            Documentation:\n",
    "            {documentation}\n",
    "\n",
    "            Provide a detailed project plan in markdown format.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        chain = RunnableSequence(prompt_template, self.llm)\n",
    "        response = chain.invoke({\"documentation\": documentation})\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Classe principal do Agente\n",
    "class Agent:\n",
    "    def __init__(self, model: Any, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.llm = model\n",
    "        \n",
    "        ktr_filename = os.path.basename(file_path)\n",
    "        self.markdown_filename = os.path.splitext(ktr_filename)[0] + \".md\"\n",
    "        \n",
    "        self.sql_analysis_agent = SQLAnalysisAgent(model)\n",
    "        self.workflow_analysis_agent = WorkflowAnalysisAgent(model)\n",
    "        self.documentation_agent = DocumentationAgent(model)\n",
    "        self.project_planning_agent = ProjectPlanningAgent(model)\n",
    "\n",
    "    def run(self):\n",
    "        state = {}\n",
    "\n",
    "        # Parse do arquivo KTR\n",
    "        state = self.parse_ktr_file(state)\n",
    "\n",
    "        # Extração da sequência de execução\n",
    "        state = self.extract_execution_sequence(state)\n",
    "\n",
    "        # Extração das consultas SQL\n",
    "        state = self.extract_sql_queries(state)\n",
    "\n",
    "        # Análise das consultas SQL\n",
    "        state = self.analyze_sql(state)\n",
    "\n",
    "        # Análise do workflow\n",
    "        state = self.analyze_workflow(state)\n",
    "\n",
    "        # Geração de documentação\n",
    "        state = self.generate_documentation(state)\n",
    "\n",
    "        # Planejamento do projeto\n",
    "        state = self.plan_project(state)\n",
    "\n",
    "        # Exporta a documentação para arquivo Markdown\n",
    "        self.export_markdown_to_file(state)\n",
    "\n",
    "    def parse_ktr_file(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        try:\n",
    "            tree = ET.parse(self.file_path)\n",
    "            state[\"root\"] = tree.getroot()\n",
    "        except ET.ParseError as e:\n",
    "            logging.error(f\"Error parsing KTR file: {e}\")\n",
    "            raise\n",
    "        return state\n",
    "\n",
    "    def extract_execution_sequence(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        hops = []\n",
    "        for hop in state[\"root\"].findall('.//hop'):\n",
    "            from_step = hop.find('from').text\n",
    "            to_step = hop.find('to').text\n",
    "            enabled = hop.find('enabled').text\n",
    "            if enabled == 'Y':\n",
    "                hops.append((from_step, to_step))\n",
    "        \n",
    "        state[\"sequence\"] = hops\n",
    "        return state\n",
    "\n",
    "    def extract_sql_queries(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        active_steps = set(step for seq in state[\"sequence\"] for step in seq)\n",
    "        sql_steps = state[\"root\"].findall(\".//step\")\n",
    "        queries = []\n",
    "        \n",
    "        for step in sql_steps:\n",
    "            step_name = step.find(\"name\").text\n",
    "            step_type = step.find(\"type\").text\n",
    "            if step_type in ['TableInput', 'DBJoin'] and step_name in active_steps:\n",
    "                sql_element = step.find(\"sql\")\n",
    "                if sql_element is not None and sql_element.text:\n",
    "                    queries.append({\n",
    "                        \"step_name\": step_name,\n",
    "                        \"step_type\": step_type,\n",
    "                        \"sql\": sql_element.text\n",
    "                    })\n",
    "        \n",
    "        state[\"queries\"] = queries\n",
    "        return state\n",
    "\n",
    "    def analyze_sql(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state[\"sql_analysis\"] = self.sql_analysis_agent.analyze(state[\"queries\"])\n",
    "        return state\n",
    "\n",
    "    def analyze_workflow(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state[\"workflow_analysis\"] = self.workflow_analysis_agent.analyze(\n",
    "            state[\"sequence\"], state[\"queries\"], state[\"sql_analysis\"]\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    def generate_documentation(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state[\"documentation\"] = self.documentation_agent.generate(\n",
    "            state[\"workflow_analysis\"], state[\"sql_analysis\"]\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    def plan_project(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state[\"project_plan\"] = self.project_planning_agent.plan(state[\"documentation\"])\n",
    "        state[\"documentation\"] += \"\\n\\n## Project Plan for Improvement\\n\\n\" + state[\"project_plan\"]\n",
    "        return state    \n",
    "\n",
    "    def export_markdown_to_file(self, state: Dict[str, Any]):\n",
    "        with open(self.markdown_filename, 'w') as file:\n",
    "            file.write(state[\"documentation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model='qwen2:latest', temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(model=model, file_path=pentaho_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
