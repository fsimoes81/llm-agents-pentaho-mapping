{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/repos/llm-agents-pentaho-mapping/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/fabio/repos/llm-agents-pentaho-mapping/.venv/lib/python3.10/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import duckdb as db\n",
    "# from pydantic import BaseModel\n",
    "from typing import Any, Dict, List, Tuple, TypedDict, Annotated\n",
    "from textwrap import dedent\n",
    "# from crewai_tools import tool, FileWriterTool\n",
    "from crewai import Agent, Crew, Process, Task\n",
    "# from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrewAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ChatGroq(\n",
    "#     model=\"llama3-8b-8192\",\n",
    "#     temperature = 0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ChatGoogleGenerativeAI(\n",
    "#     model='gemini-1.5-pro-exp-0801',\n",
    "#     temperature=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_list(file_path: str) -> List:\n",
    "    with open(file_path) as f:\n",
    "        s = f.read()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(folder_path: str):\n",
    "    file_list = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]\n",
    "    file_list.sort()\n",
    "    queries = []  \n",
    "\n",
    "    for sql_file in file_list:\n",
    "        q = query_list(join(folder_path,sql_file))\n",
    "        queries.append({\n",
    "            'query_name': sql_file[:-4],\n",
    "            'sql_code': q \n",
    "        })          \n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'sql_files/bn_beneficiario/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_analyst = Agent(\n",
    "    role = \"Senior Data Analyst\",\n",
    "    goal = \"Analyze and complicate SQL queries and extract the relationship between table name and column name of all tables in queries.\",\n",
    "    backstory=dedent(\n",
    "        \"\"\"\n",
    "        You're a highly specialized developed to dissect and understand complex SQL queries,\n",
    "        you could quickly and accurately extract essential information from intricate SQL statements, \n",
    "        including that ones that has many sub queries.\n",
    "        Your key traits are Analytical prowess, Attention to detail, Vast knowledge of SQL syntax \n",
    "        across multiple database systems.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    llm=model,\n",
    "    allow_delegation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_table_names = Task(\n",
    "    description=dedent(\n",
    "        \"\"\" \n",
    "        Search this SQL query {sql_code} for all table names involved.\n",
    "        It is very important not to ignore any tables. In complex queries, \n",
    "        there are some subqueries that must be observed carefully.\n",
    "        Do it line by line, get all table names and their alias when they are present.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    expected_output=\"List of distinct table names and alias present in the query.\",\n",
    "    agent=sql_analyst,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_tables_columns = Task(\n",
    "    description=dedent(\n",
    "        \"\"\"\n",
    "        Analyse this SQL querie {sql_code}.\n",
    "        Use the list of table names and their aliases extracted in the previous step and find the columns for each of these tables.\n",
    "        Then extract the names of related tables and columns. For this walkthrough, you will get all the table and column names used in this query.\n",
    "        Get just the table name and column name by following these patterns:\n",
    "        table_name;alias;columns_name\n",
    "        table1;alias1;columnName_n1\n",
    "        table1;alias1;columnName_n2\n",
    "        table2;alias2;columnName_n1\n",
    "        table2;alias2;columnName_n2\n",
    "        tableN;aliasN;columnName_n1\n",
    "        tableN;aliasN;columnName_n1\n",
    "        \"\"\"\n",
    "    ),\n",
    "    expected_output=\"CSV file\",\n",
    "    agent=sql_analyst,\n",
    "    context=[get_table_names]\n",
    "    #callback=lambda result: result_collector.add_result(result)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rules = Task(\n",
    "    description=dedent(\n",
    "        \"\"\"\n",
    "        Analyse this SQL querie {sql_code}.\n",
    "        Use the csv file generated in the previous step and find and extract following points:\n",
    "        * SQL code where sql functions are used such as NVL, DECODE, CASE, SUM, etc, or concatenations lets call it of rules.\n",
    "        * After rules we can find the alias for the column, the alias names are the final names given to the columns in the query. \n",
    "        Then step by step extract the column names, the alias, and the rule that gave rise to the alias.\n",
    "        Get column_name, alias, and rule, following these patterns only for columns were you find rules:\n",
    "        columns_name;alias;rule\n",
    "        columnName_n1;alias_n1;\"rule_n1\"\n",
    "        columnName_n2;alias_n2;\"rule_n2\"\n",
    "        columnName_n3;alias_n3;\"rule_n3\"\n",
    "        columnName_nn;alias_nn;\"rule_nn\"\n",
    "        \"\"\"\n",
    "    ),\n",
    "    expected_output=\"CSV file\",\n",
    "    agent=sql_analyst,\n",
    "    context=[extract_tables_columns]\n",
    "    #callback=lambda result: result_collector.add_result(result)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 15:16:53,654 - 130117974093824 - __init__.py-__init__:531 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "crew = Crew(\n",
    "    agents = [sql_analyst],\n",
    "    tasks = [get_table_names, extract_tables_columns, extract_rules],\n",
    "    process = Process.sequential,\n",
    "    verbose = 0,\n",
    "    memory=False,\n",
    "    output_log_file=\"crew.log\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "##self.export_to_csv()\n",
    "\n",
    "def save_to_csv(data, filename, header: list):\n",
    "    # Split the string by newlines to get rows\n",
    "    rows = data.split('\\n')\n",
    "    \n",
    "    # Split each row by semicolons to get columns\n",
    "    formatted_data = [row.split(';') for row in rows]\n",
    "    \n",
    "    # Output filename\n",
    "    output_filename = f\"{'output'}/{filename}.csv\"\n",
    "\n",
    "    # Write the formatted data to a CSV file\n",
    "    with open(output_filename, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter=',',quotechar =',',quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(header)  # Write header\n",
    "        writer.writerows(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_beneficiario\n",
      "02_sam_familia_teto_pf\n",
      "03_1_busca_microsiga\n",
      "03_2_sem_setor\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query['query_name'])\n",
    "    file_name = query['query_name']\n",
    "    result = crew.kickoff(inputs=query)\n",
    "    task_output = extract_tables_columns.output\n",
    "    save_to_csv(task_output.raw, file_name, ['table','alias','column_name'])\n",
    "    task_output = extract_rules.output\n",
    "    save_to_csv(task_output.raw, file_name+'_rules', ['column_name','alias','rule'])\n",
    "\n",
    "    #result_collector.add_result('export_tables_columns',output.raw,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processa CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\n",
    "\"\"\"     \n",
    "    with ben_ori as (\n",
    "        select * from 'output/01_beneficiario.csv' \n",
    "        union all\n",
    "        select * from 'output/02_sam_familia_teto_pf.csv' \n",
    "        union all\n",
    "        select * from 'output/03_1_busca_microsiga.csv'\n",
    "        union all\n",
    "        select * from 'output/03_2_sem_setor.csv'\n",
    "    ),\n",
    "    ben_rul as (\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/01_beneficiario_rules.csv'\n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/02_sam_familia_teto_pf_rules.csv' \n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/03_1_busca_microsiga_rules.csv'\n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule        \n",
    "        from 'output/03_2_sem_setor_rules.csv'\n",
    "    ),\n",
    "    ben_dest as (\n",
    "        select * from 'output/99_bn_beneficiario.csv'\n",
    "    )\n",
    "    select \n",
    "        distinct \n",
    "        ben_dest.*,\n",
    "        ben_ori.*,\n",
    "        ben_rul.*\n",
    "    from ben_dest\n",
    "    left join ben_ori \n",
    "    on(ben_ori.column_name = ben_dest.column_name)\n",
    "    left join ben_rul\n",
    "    on(ben_dest.colum_name_renamed = ben_rul.alias)\n",
    "    order by ben_ori.column_name\n",
    "\"\"\").to_csv('duckdb_output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────┬──────────────────────┬────────────────────────────────────────────────────────────────────────┐\n",
       "│     column_name      │        alias         │                                  rule                                  │\n",
       "│       varchar        │       varchar        │                                varchar                                 │\n",
       "├──────────────────────┼──────────────────────┼────────────────────────────────────────────────────────────────────────┤\n",
       "│ DATACANCELAMENTO     │ DATA_CANCELAMENTO    │ CASE WHEN BEN.DATACANCELAMENTO < SYSDATE THEN BEN.DATACANCELAMENTO W…  │\n",
       "│ MOTIVOCANCELAMENTO   │ MOTIVO_CANC          │ CASE WHEN BEN.DATACANCELAMENTO < SYSDATE THEN BEN.MOTIVOCANCELAMENTO…  │\n",
       "│ MOTIVOCANCELAMENTO   │ MOTIVO_CANC          │ CASE WHEN BEN.DATACANCELAMENTO < SYSDATE THEN MCAN.DESCRICAO WHEN MC…  │\n",
       "│ MOTIVOINCLUSAO       │ MOTIVO_INCLUSAO      │ CASE WHEN BEN.MOTIVOINCLUSAO = 5 THEN 'Novo beneficiário' WHEN BEN.M…  │\n",
       "│ NAOTEMCARENCIA       │ NAO_TEM_CARENCIA     │ DECODE(BEN.NAOTEMCARENCIA, 'S','Sim','N','Não')                        │\n",
       "│ SOFREUADAPTACAO      │ SOFREU_ADAPTACAO     │ DECODE(BEN.SOFREUADAPTACAO, 1,'Não',2,'Sim')                           │\n",
       "│ TABORIGEM            │ ORIGEM               │ DECODE(BEN.TABORIGEM, 1,'Próprio',2,'Assumido',3,'Assumido-Eventual')  │\n",
       "│ BLOQUEIARECADBIOAU…  │ BLOQUEAR_RECAD_BIO…  │ DECODE(BEN.BLOQUEIARECADBIOAUTORIZADORWEB,'S','Sim','N','Não')         │\n",
       "│ COBRANCANOMESSEGUI…  │ COBRANCA_MES_SEGUI…  │ DECODE(FAM.COBRANCANOMESSEGUINTE,'S','Sim','N','Não')                  │\n",
       "│ DATACANCELAMENTO     │ DATA_CANCELAMENTO    │ CASE WHEN BEN.DATACANCELAMENTO < SYSDATE THEN BEN.DATACANCELAMENTO W…  │\n",
       "│      ·               │      ·               │                  ·                                                     │\n",
       "│      ·               │      ·               │                  ·                                                     │\n",
       "│      ·               │      ·               │                  ·                                                     │\n",
       "│ BENEFICIARIO         │ BENEFICIARIO         │ NVL(TRIM(BEN.Z_NOME),TRIM(BEN.NOME))                                   │\n",
       "│ DATACANCELAMENTO     │ DATA_CANCELAMENTO    │ CASE WHEN BEN.DATACANCELAMENTO < SYSDATE THEN BEN.DATACANCELAMENTO W…  │\n",
       "│ DATAINICIAL          │ DATA_INICIAL_TETO_…  │ DATAINICIAL                                                            │\n",
       "│ DATAFINAL            │ DATA_FINAL_TETO_CO…  │ DATAFINAL                                                              │\n",
       "│ VALORTETOPF          │ VALOR_TETO_COBRANCA  │ VALORTETOPF                                                            │\n",
       "│ CTT_DESC01           │ SETOR_UNIMED         │ TRIM(B.CTT_DESC01)                                                     │\n",
       "│ RA_TELEFON           │ TELEFONE             │ TRIM(A.RA_TELEFON)                                                     │\n",
       "│ DDD1                 │ TELEFONE             │ ('||ENDR.DDD1||') '||ENDR.PREFIXO1||'-'||ENDR.NUMERO1                  │\n",
       "│ PREFIXO1             │ TELEFONE             │ ('||ENDR.DDD1||') '||ENDR.PREFIXO1||'-'||ENDR.NUMERO1                  │\n",
       "│ NUMERO1              │ TELEFONE             │ ('||ENDR.DDD1||') '||ENDR.PREFIXO1||'-'||ENDR.NUMERO1                  │\n",
       "├──────────────────────┴──────────────────────┴────────────────────────────────────────────────────────────────────────┤\n",
       "│ 27 rows (20 shown)                                                                                         3 columns │\n",
       "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.sql(\n",
    "\"\"\"     \n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/01_beneficiario_rules.csv'\n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/02_sam_familia_teto_pf_rules.csv' \n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule\n",
    "        from 'output/03_1_busca_microsiga_rules.csv'\n",
    "        union all\n",
    "        select \n",
    "            SUBSTR(column_name, INSTR(column_name, '.') + 1) AS column_name,\n",
    "            alias,\n",
    "            rule        \n",
    "        from 'output/03_2_sem_setor_rules.csv'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────┬──────────┬───────────────────────────────────────────────────────┐\n",
       "│  column_name  │  alias   │                         rule                          │\n",
       "│    varchar    │ varchar  │                        varchar                        │\n",
       "├───────────────┼──────────┼───────────────────────────────────────────────────────┤\n",
       "│ ENDR.DDD1     │ TELEFONE │ ('||ENDR.DDD1||') '||ENDR.PREFIXO1||'-'||ENDR.NUMERO1 │\n",
       "│ ENDR.PREFIXO1 │ TELEFONE │ ('||ENDR.DDD1||') '||ENDR.PREFIXO1||'-'||ENDR.NUMERO1 │\n",
       "│ ENDR.NUMERO1  │ TELEFONE │ ('||ENDR.DDD1||') '||ENDR.PREFIXO1||'-'||ENDR.NUMERO1 │\n",
       "└───────────────┴──────────┴───────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.read_csv('output/03_2_sem_setor_rules.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
